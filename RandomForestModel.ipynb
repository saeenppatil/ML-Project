{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98f9383-be75-4447-9999-5daf7e1ba564",
   "metadata": {},
   "source": [
    "Default Model with no hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c3f5428-f117-4e62-8d17-355a1c894ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('breastcancer.csv') \n",
    "\n",
    "features_selected = ['radius_mean', 'texture_mean', 'smoothness_mean', 'compactness_mean', \n",
    "                     'concavity_mean', 'symmetry_mean', 'radius_se', 'concave points_se', \n",
    "                     'smoothness_worst', 'compactness_worst', 'concavity_worst', \n",
    "                     'symmetry_worst', 'fractal_dimension_worst'] # Features that were highly correlated when feature selection was done\n",
    "\n",
    "\n",
    "X = data[features_selected]\n",
    "y = data['diagnosis']\n",
    "\n",
    "X = X.dropna()\n",
    "y = y.dropna()\n",
    "\n",
    "X = X.loc[y.index] # make sure X & y line up together\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "\n",
    "num_features = len(features_selected) # Number of features to complete square root of\n",
    "\n",
    "# Random Forest Model Implementation\n",
    "random_forest = RandomForestClassifier(max_features = math.ceil(math.sqrt(num_features)), n_estimators = 5, random_state=23)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest Accuracy: {accuracy_rf:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23240512-fcd2-4249-bae1-c11ec562bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 4, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 5, 'n_jobs': None, 'oob_score': False, 'random_state': 23, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Print all the parameters of the random forest out\n",
    "print(\"Random Forest Model Parameters:\", random_forest.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3895e-3f85-4dbf-9e66-31266e089a3e",
   "metadata": {},
   "source": [
    "Perform Hyperparameter Tuning using Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf2ed47e-796c-4a94-ba8a-f6b825159370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=23) #initialize\n",
    "\n",
    "# Hyperparameter tuning using grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1, cv=5, error_score = 'raise') # Perform grid search with cv folds of 5\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fef39-bc0d-4720-866c-16a16b0d1e22",
   "metadata": {},
   "source": [
    "Updated Random Forest Model using the best parameters from the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "731f34d5-8985-4bf5-ab82-7c01d0a814b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model Implementation with best parameters\n",
    "best_rf = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=100,\n",
    "    random_state=23\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "\n",
    "# Print the accuracy of the best Random Forest model\n",
    "print(f'Best Random Forest Accuracy: {accuracy_best_rf:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
